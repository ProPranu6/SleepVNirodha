{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Objectives of the notebook\n* Run, save the version and download the trained model for various time window sizes mentioned below\n    * 100ms, 200ms, 300ms, 400ms, 500ms, 600ms, 700ms, 800ms, 900ms\n* Document the confusion matrices, classwise accuracies and training graphs of all the above models in a google document.\n\n* Repeat the below mentioned instructions for all the time-window sizes\n\n### Instructions to run and save the version of this notebook\n\n* Move to the first code cell under \"Scratch Training on Default Preprocessed Data\" section below, and replace the value of \"samples\" variable according to the calculation mentioned in the comments section by plugging in \"n\" milli seconds, where n is a milli second in the given list above\n\n* Now go to the next code block below and change the value of \"twms\" to the nth milli second that is taken\n\n* Now click on \"Run all\" from the \"run\" option on the navigation bar of kaggle\n\n* After the notebook has run and after documenting the results, click on save version and name the version in the format as \"SleepVNirodha:EEGNet-DefaultPreprocessed-nms\" here in place of \"nms\" replace \"nth milli second value\" + \"ms\". Eg : 1000ms, 200ms etc. Also ensure that while saving version you click on \"quick save\" in the drop down menu.\n\n* Now from the \"/kaggle/working\" directory in the Output section, locate the downloaded model zip file and place it in the research google drive under \"SleepVNirodha Models/DefaultPreprocessed\" directory.  \n\n\n##### PS : An example version (in kaggle), trained model (in drive), and results (in drive) can be found for your reference","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n!pip install pyedflib\n!pip install pyriemann\n!pip install mne\n!pip install pymatreader\n!pip install --upgrade gdown","metadata":{"execution":{"iopub.status.busy":"2023-03-25T15:38:16.999757Z","iopub.execute_input":"2023-03-25T15:38:17.000559Z","iopub.status.idle":"2023-03-25T15:39:31.651883Z","shell.execute_reply.started":"2023-03-25T15:38:17.000516Z","shell.execute_reply":"2023-03-25T15:39:31.650243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.9.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pyedflib\n  Downloading pyEDFlib-0.1.30-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from pyedflib) (1.21.6)\nInstalling collected packages: pyedflib\nSuccessfully installed pyedflib-0.1.30\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pyriemann\n  Downloading pyriemann-0.4.tar.gz (90 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy!=1.24.0 in /opt/conda/lib/python3.7/site-packages (from pyriemann) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pyriemann) (1.7.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pyriemann) (1.0.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from pyriemann) (1.2.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pyriemann) (1.3.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pyriemann) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pyriemann) (2022.7.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pyriemann) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->pyriemann) (1.16.0)\nBuilding wheels for collected packages: pyriemann\n  Building wheel for pyriemann (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyriemann: filename=pyriemann-0.4-py2.py3-none-any.whl size=105118 sha256=7d31fd0a18e4fe779a3f23c76a92e7a0666e17d2056eb49875b6973807cac00b\n  Stored in directory: /root/.cache/pip/wheels/ec/fe/76/f163a0461617fb262888564706c38d65d963d2157cbf97c078\nSuccessfully built pyriemann\nInstalling collected packages: pyriemann\nSuccessfully installed pyriemann-0.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: mne in /opt/conda/lib/python3.7/site-packages (1.3.0)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.7/site-packages (from mne) (1.6.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from mne) (1.7.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from mne) (3.1.2)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from mne) (5.1.1)\nRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.7/site-packages (from mne) (1.21.6)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from mne) (4.64.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mne) (23.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mne) (3.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.5->mne) (2.28.2)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.5->mne) (1.4.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->mne) (2.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (9.4.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (4.38.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (3.0.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.14)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pymatreader\n  Downloading pymatreader-0.0.30-py3-none-any.whl (9.0 kB)\nRequirement already satisfied: scipy!=1.7.0 in /opt/conda/lib/python3.7/site-packages (from pymatreader) (1.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pymatreader) (1.21.6)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pymatreader) (0.18.3)\nCollecting xmltodict\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from pymatreader) (3.8.0)\nInstalling collected packages: xmltodict, pymatreader\nSuccessfully installed pymatreader-0.0.30 xmltodict-0.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.7.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.9.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Import required libraries and classes**","metadata":{"id":"xLEW1az535Z7"}},{"cell_type":"code","source":"import sys\nimport os\nif os.path.exists('/kaggle/input/myeegmodules'):\n    gdrive_dataset_dir = '/kaggle/working/'\n    sys.path.append('/kaggle/input/myeegmodules')\nelse :\n    gdrive_dataset_dir = ''\n    pass\nfrom eegnet_logics import *","metadata":{"execution":{"iopub.status.busy":"2023-03-25T15:41:51.900441Z","iopub.execute_input":"2023-03-25T15:41:51.900853Z","iopub.status.idle":"2023-03-25T15:42:05.482031Z","shell.execute_reply.started":"2023-03-25T15:41:51.900819Z","shell.execute_reply":"2023-03-25T15:42:05.480547Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**To Download PreProcessed Data**","metadata":{}},{"cell_type":"code","source":"import gdown\nidd = \"1fJGVMQTxZynmbvr4IxSX02_yL60sSvnH\"\ngdown.download(id=idd, quiet=False)\n\nidd = \"1kcKDjJ7kwhGlXLG80s9qxCSpOeXApIYa\"\ngdown.download(id=idd, quiet=False,)\n\nidd = \"1J19wA9Q0ZBdBLjG3n9RDHWEiPPmbSiBv\"\ngdown.download(id=idd, quiet=False, )\n\nidd = \"1rJlOAuyG5QR-jA4b43tnye3uG_gVrwTw\"\ngdown.download(id=idd, quiet=False, )","metadata":{"execution":{"iopub.status.busy":"2023-03-25T15:42:15.872117Z","iopub.execute_input":"2023-03-25T15:42:15.872948Z","iopub.status.idle":"2023-03-25T15:42:40.109666Z","shell.execute_reply.started":"2023-03-25T15:42:15.872904Z","shell.execute_reply":"2023-03-25T15:42:40.108433Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1fJGVMQTxZynmbvr4IxSX02_yL60sSvnH\nFrom (redirected): https://drive.google.com/uc?id=1fJGVMQTxZynmbvr4IxSX02_yL60sSvnH&confirm=t&uuid=38a7a90c-860b-4080-8261-5e6062528cd3\nTo: /kaggle/working/SUB200921 - 20210920T132431.set\n100%|██████████| 904M/904M [00:06<00:00, 146MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=1kcKDjJ7kwhGlXLG80s9qxCSpOeXApIYa\nTo: /kaggle/working/SUB200921-2 - 20210920T164137.set\n100%|██████████| 53.8M/53.8M [00:00<00:00, 70.4MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1J19wA9Q0ZBdBLjG3n9RDHWEiPPmbSiBv\nTo: /kaggle/working/SUB200921-3 - 20210920T165003.set\n100%|██████████| 83.5M/83.5M [00:00<00:00, 104MB/s] \nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1rJlOAuyG5QR-jA4b43tnye3uG_gVrwTw\nFrom (redirected): https://drive.google.com/uc?id=1rJlOAuyG5QR-jA4b43tnye3uG_gVrwTw&confirm=t&uuid=bc4bbd34-ac79-4594-a60f-05c2f3ce0632\nTo: /kaggle/working/SUB200921-4 - 20210920T170117.set\n100%|██████████| 846M/846M [00:06<00:00, 131MB/s]  \n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'SUB200921-4 - 20210920T170117.set'"},"metadata":{}}]},{"cell_type":"markdown","source":"# **EEGNet Model**\n\n\n```\ndef EEGNet_tensorflow(nb_classes, Chans = 64, Samples = 128, \n             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n    \"\"\" Keras Implementation of EEGNet\n    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n    \"\"\"\n    \n    input1   = Input(shape = (Chans, Samples, 1))\n\n    ##################################################################(Chans, Samples, 1)\n    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n                                   use_bias = False)(input1)\n    block1       = BatchNormalization()(block1)\n    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n                                   depth_multiplier = D,\n                                   depthwise_constraint = max_norm(1.))(block1)\n    block1       = BatchNormalization()(block1)\n    block1       = Activation('elu')(block1)\n    block1       = AveragePooling2D((1, 4))(block1)\n    block1       = dropoutType(dropoutRate)(block1)\n    \n    block2       = SeparableConv2D(F2, (1, 16),\n                                   use_bias = False, padding = 'same')(block1)\n    block2       = BatchNormalization()(block2)\n    block2       = Activation('elu')(block2)\n    block2       = AveragePooling2D((1, 8))(block2)\n    block2       = dropoutType(dropoutRate)(block2)\n        \n    flatten      = Flatten(name = 'flatten')(block2)\n    \n    dense        = Dense(nb_classes, name = 'dense', \n                         kernel_constraint = max_norm(norm_rate))(flatten)\n    softmax      = Activation('softmax', name = 'softmax')(dense)\n    \n    return Model(inputs=input1, outputs=softmax)\n```\n\n","metadata":{"id":"IDfDo3HZ38pK"}},{"cell_type":"markdown","source":"## **Scratch Training on Default PreProcessed Data**","metadata":{"id":"OjWejEh5R4GW"}},{"cell_type":"code","source":"import os\ndata_sampling_rate = 512\nchans, samples, kernels = 64, 512, 1  #(n in milli seconds/1000)*512\ntrain_batch_size, test_batch_size = 1024, 128\ndata_paths =  [f'{gdrive_dataset_dir}SUB200921 - 20210920T132431.set', f'{gdrive_dataset_dir}SUB200921-2 - 20210920T164137.set', f'{gdrive_dataset_dir}SUB200921-3 - 20210920T165003.set', f'{gdrive_dataset_dir}SUB200921-4 - 20210920T170117.set'] #full nap, awake at rest, awake and talking, meditating\ndata_paths_only_2 = [data_paths[0], data_paths[3]]\n\ndataset_creator = EEGAsDatasetCreator(dataset_dir=f'{gdrive_dataset_dir}sleepvnirodha', limit_data_seconds=7200,data_resample=data_sampling_rate, channels=chans,data_time_steps=samples, data_paths=data_paths_only_2, train_split_per_recording=0.8, shuffle_before_record_split=False, scale=1e9)\ntrain_dataset_generator = dataset_creator(f'{gdrive_dataset_dir}sleepvnirodha/train', batch_size=train_batch_size)\ntest_dataset_generator = dataset_creator(f'{gdrive_dataset_dir}sleepvnirodha/test', batch_size=test_batch_size)\n\ntrain_samples, test_samples = len(os.listdir(f'{gdrive_dataset_dir}sleepvnirodha/train')), len(os.listdir(f'{gdrive_dataset_dir}sleepvnirodha/test'))\nprint(\"Total Train samples : \", train_samples)\nprint(\"Total Test samples : \", test_samples)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T15:43:05.195256Z","iopub.execute_input":"2023-03-25T15:43:05.196066Z","iopub.status.idle":"2023-03-25T15:45:03.133780Z","shell.execute_reply.started":"2023-03-25T15:43:05.196020Z","shell.execute_reply":"2023-03-25T15:45:03.131786Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pymatreader/utils.py:122: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n  warn('Complex objects (like classes) are not supported. '\n/kaggle/input/myeegmodules/eegnet_logics.py:495: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n  raw = mne.io.read_raw_eeglab(f'{path}') # mne.io.read_raw_bdf(f'{path}', infer_types=True)\n/opt/conda/lib/python3.7/site-packages/pymatreader/utils.py:122: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n  warn('Complex objects (like classes) are not supported. '\n/kaggle/input/myeegmodules/eegnet_logics.py:495: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n  raw = mne.io.read_raw_eeglab(f'{path}') # mne.io.read_raw_bdf(f'{path}', infer_types=True)\n","output_type":"stream"},{"name":"stdout","text":"Total Train samples :  11017\nTotal Test samples :  2755\n","output_type":"stream"}]},{"cell_type":"code","source":"from math import ceil\ntrain_steps = ceil(train_samples/train_batch_size)\ntest_steps = ceil(test_samples/test_batch_size)\ngenerator_info = {'train_generator' : train_dataset_generator, 'test_generator' : test_dataset_generator, 'steps_per_train_epoch': train_steps, 'steps_per_test_epoch' : test_steps}","metadata":{"execution":{"iopub.status.busy":"2023-03-25T15:45:40.851813Z","iopub.execute_input":"2023-03-25T15:45:40.853467Z","iopub.status.idle":"2023-03-25T15:45:40.862214Z","shell.execute_reply.started":"2023-03-25T15:45:40.853405Z","shell.execute_reply":"2023-03-25T15:45:40.860762Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(6)\nprmodel = EEGNet_tensorflow(nb_classes = 2, Chans = chans, Samples = samples, \n               dropoutRate = 0.25, kernLength = data_sampling_rate//2, F1 = 8, D = 2, F2 = 16, \n               dropoutType = 'Dropout')\ntrainer = TrainingSleepVNirodha(model=prmodel, channels=chans, sever_model_top=False, out_classes=None)    \nfinetuned_model = trainer(epochs=50, progressive_data_load=True, generator_info=generator_info, lr=1e-3)\ntwms = 1000 #insert the nth milli second value here\nmodel_name = f'EEGNet-DefaultPreprocessed-SleepVNirodha-TW{twms}ms'\ntrainer.model.save(f'{model_name}')\n\nfrom IPython.display import FileLink\nimport shutil\nshutil.make_archive(f'{model_name}-Model', 'zip', f'{model_name}')\n\n#print(\"Per sample Accuracy\")\n#trainer.get_stats(mode='per_sample_acc')\n#print(\"Classwise Per sample accuracy\")\n#trainer.get_stats(mode='per_class_acc')\n#print(\"Recordwise Per sample Accuracy\")\n#trainer.get_stats(mode='per_rec_acc')\n#print(\"Recordwise Votings\")\n#trainer.get_stats(mode='per_rec_vot')\n","metadata":{"id":"DOGsgNhklmx9","outputId":"26dd8fae-c0a1-4e13-d197-5fa508a75818","execution":{"iopub.status.busy":"2023-03-25T15:45:56.912472Z","iopub.execute_input":"2023-03-25T15:45:56.912877Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"====================Model Architecture====================\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 64, 512, 1)]      0         \n                                                                 \n conv2d (Conv2D)             (None, 64, 512, 8)        2048      \n                                                                 \n batch_normalization (BatchN  (None, 64, 512, 8)       32        \n ormalization)                                                   \n                                                                 \n depthwise_conv2d (Depthwise  (None, 1, 512, 16)       1024      \n Conv2D)                                                         \n                                                                 \n batch_normalization_1 (Batc  (None, 1, 512, 16)       64        \n hNormalization)                                                 \n                                                                 \n activation (Activation)     (None, 1, 512, 16)        0         \n                                                                 \n average_pooling2d (AverageP  (None, 1, 128, 16)       0         \n ooling2D)                                                       \n                                                                 \n dropout (Dropout)           (None, 1, 128, 16)        0         \n                                                                 \n separable_conv2d (Separable  (None, 1, 128, 16)       512       \n Conv2D)                                                         \n                                                                 \n batch_normalization_2 (Batc  (None, 1, 128, 16)       64        \n hNormalization)                                                 \n                                                                 \n activation_1 (Activation)   (None, 1, 128, 16)        0         \n                                                                 \n average_pooling2d_1 (Averag  (None, 1, 16, 16)        0         \n ePooling2D)                                                     \n                                                                 \n dropout_1 (Dropout)         (None, 1, 16, 16)         0         \n                                                                 \n flatten (Flatten)           (None, 256)               0         \n                                                                 \n dense (Dense)               (None, 2)                 514       \n                                                                 \n softmax (Activation)        (None, 2)                 0         \n                                                                 \n=================================================================\nTotal params: 4,258\nTrainable params: 4,178\nNon-trainable params: 80\n_________________________________________________________________\nNone\n====================Organising Data====================\n====================Training Model====================\nEpoch 1/50\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ypreds, Y = [], []\nfor batch in range(test_steps):\n    x, y = next(test_dataset_generator)\n    ypred = np.argmax(trainer.model.predict(x), axis=-1)\n    Ypreds.append(ypred)\n    Y.append(y)\n\nYpreds = np.concatenate(Ypreds, axis=0)\nY = np.concatenate(Y, axis=0)\nYpreds.shape, Y.shape","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:50.533471Z","iopub.status.busy":"2023-03-25T13:51:50.531422Z","iopub.status.idle":"2023-03-25T13:51:58.198419Z","shell.execute_reply":"2023-03-25T13:51:58.197505Z","shell.execute_reply.started":"2023-03-25T13:51:50.533438Z"}},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["((2816,), (2816,))"]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import metrics\n\nactual = Y\npredicted = Ypreds\n\nconfusion_matrix = metrics.confusion_matrix(actual, predicted)\n\ncm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Sleep\", \"Nirodha\"])\n\ncm_display.plot()\nplt.show()\n\nclass_samples_counts = np.sum(confusion_matrix, axis=1)\nprint(f\"Sleep Accuracy : {(confusion_matrix[0][0]/class_samples_counts[0])*100}%\")\nprint(f\"Nirodha Accuracy : {(confusion_matrix[1][1]/class_samples_counts[1])*100}%\")\nprint(f\"Overall Accuracy : {(confusion_matrix[0][0] + confusion_matrix[1][1])*100/(sum(class_samples_counts))}%\")","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.200271Z","iopub.status.busy":"2023-03-25T13:51:58.199908Z","iopub.status.idle":"2023-03-25T13:51:58.412553Z","shell.execute_reply":"2023-03-25T13:51:58.411515Z","shell.execute_reply.started":"2023-03-25T13:51:58.200234Z"}},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}},{"name":"stdout","output_type":"stream","text":"Sleep Accuracy : 83.97260273972603%\n\nNirodha Accuracy : 34.14454277286136%\n\nOverall Accuracy : 59.97869318181818%\n"}]},{"cell_type":"markdown","source":"### Playground","metadata":{}},{"cell_type":"markdown","source":"%% don't mind the below table\n### Model Predictions on 1000ms Sample Sizes and Preprocessed Data (as given)\n\n\n**Full Napping** : 74% accuracy\n**Meditating** : 83% accuracy\n**Overall** : 78.5% accuracy\n\n### Confusion Matrix :\n|Act/Pred->                 |   Full Napping |      Meditating     |      Total      |\n|---------------------------|----------------|---------------------|-----------------|\n|**Full Napping**           |       74       |          26         |       100       |\n|**Meditating**             |       17       |          83         |       100       |                 \n|**Total**                  |       91       |          109        |       200       |         \n  ","metadata":{}},{"cell_type":"code","source":"%%script echo skipping\nfrom keras.callbacks import Callback\nclass AdditionalValidationSets(Callback):\n    def __init__(self, validation_sets, verbose=0, batch_size=None):\n        \"\"\"\n        :param validation_sets:\n        a list of 3-tuples (validation_data, validation_targets, validation_set_name)\n        or 4-tuples (validation_data, validation_targets, sample_weights, validation_set_name)\n        :param verbose:\n        verbosity mode, 1 or 0\n        :param batch_size:\n        batch size to be used when evaluating on the additional datasets\n        \"\"\"\n        super(AdditionalValidationSets, self).__init__()\n        self.validation_sets = validation_sets\n        for validation_set in self.validation_sets:\n            if len(validation_set) not in [3, 4]:\n                raise ValueError()\n        self.epoch = []\n        self.history = {}\n        self.verbose = verbose\n        self.batch_size = batch_size\n\n    def on_train_begin(self, logs=None):\n      \n        self.epoch = []\n        self.history = {}\n\n    def on_epoch_end(self, epoch, logs=None):\n    \n        logs = logs or {}\n        self.epoch.append(epoch)\n\n        # record the same values as History() as well\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n\n        # evaluate on the additional validation sets\n        for validation_set in self.validation_sets:\n            if len(validation_set) == 3:\n                validation_data, validation_targets, validation_set_name = validation_set\n                sample_weights = None\n            elif len(validation_set) == 4:\n                validation_data, validation_targets, sample_weights, validation_set_name = validation_set\n            else:\n                raise ValueError()\n           \n            results = self.model.evaluate(x=validation_data,\n                                          y=validation_targets,\n                                          verbose=self.verbose,\n                                          sample_weight=sample_weights,\n                                          batch_size=self.batch_size)\n\n            for metric, result in zip(self.model.metrics_names,results):\n                valuename = validation_set_name + '_' + metric\n                self.history.setdefault(valuename, []).append(result)\n                print(f'{valuename} : {result}')\n        ","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.414482Z","iopub.status.busy":"2023-03-25T13:51:58.414112Z","iopub.status.idle":"2023-03-25T13:51:58.559800Z","shell.execute_reply":"2023-03-25T13:51:58.558625Z","shell.execute_reply.started":"2023-03-25T13:51:58.414446Z"}},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"skipping\n"}]},{"cell_type":"code","source":"%%script echo skipping\nval1 = (trainer.X_test_in_rec_partitions[0], np.array(trainer.Y_test_in_rec_partitions[0]))\nval2 = (trainer.X_test_in_rec_partitions[1], np.array(trainer.Y_test_in_rec_partitions[1]))\ntrainx, trainy = trainer.X, trainer.Y \nhistory = AdditionalValidationSets([ val2 + ('val2',)])","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.563728Z","iopub.status.busy":"2023-03-25T13:51:58.563386Z","iopub.status.idle":"2023-03-25T13:51:58.660910Z","shell.execute_reply":"2023-03-25T13:51:58.659734Z","shell.execute_reply.started":"2023-03-25T13:51:58.563685Z"}},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"skipping\n"}]},{"cell_type":"code","source":"%%script echo skipping\nnew_history = finetuned_model.fit(trainx, trainy,\n          epochs=100,\n          batch_size=128,\n          validation_data=val1,\n          callbacks=[history])","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.663658Z","iopub.status.busy":"2023-03-25T13:51:58.663033Z","iopub.status.idle":"2023-03-25T13:51:58.763849Z","shell.execute_reply":"2023-03-25T13:51:58.762667Z","shell.execute_reply.started":"2023-03-25T13:51:58.663606Z"}},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"skipping\n"}]},{"cell_type":"code","source":"%%script echo skipping\nlogits = finetuned_model.predict(trainer.X_test) \npreds = np.argmax(logits, axis=-1)\nprint(\"Mean Logit prediction of Full napping class\", np.mean(logits[trainer.Y_test==0], axis=0))\nprint(\"Mean Logit prediction of Meditating class\", np.mean(logits[trainer.Y_test==1], axis=0))","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.766602Z","iopub.status.busy":"2023-03-25T13:51:58.766172Z","iopub.status.idle":"2023-03-25T13:51:58.864694Z","shell.execute_reply":"2023-03-25T13:51:58.863483Z","shell.execute_reply.started":"2023-03-25T13:51:58.766556Z"}},"execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"skipping\n"}]},{"cell_type":"code","source":"%%script echo skipping\nimport matplotlib.pyplot as plt\n\nlimit = 25\nepochs = np.arange(limit)\n\ntotal_train_loss = history.history['loss'][:limit]\nsleep_loss = history.history['val_loss'][:limit]\nmeditating_loss = history.history['val2_loss'][:limit]\ntotal_val_loss = 0.5*np.array(sleep_loss) + 0.5*np.array(meditating_loss) \n\n\ntotal_train_acc = history.history['accuracy'][:limit]\nsleep_acc = history.history['val_accuracy'][:limit]\nmeditating_acc = history.history['val2_accuracy'][:limit]\ntotal_val_acc = 0.5*np.array(sleep_acc) + 0.5*np.array(meditating_acc) \n\nplt.figure(figsize=(20, 6))\nplt.subplot(1,2,1)\nplt.title(\"Loss Curves\")\nplt.plot(epochs, total_val_loss, color=\"red\")\n#plt.plot(epochs, sleep_loss, color=\"black\")\nplt.plot(epochs, meditating_loss, color=\"orange\")\n#plt.plot(epochs, total_train_loss, color=\"green\")\nplt.legend(['total val loss', 'sleep loss', 'meditating loss', 'total train loss'])\n\nplt.subplot(1,2,2)\nplt.title(\"Accuracy Curves\")\nplt.plot(epochs, total_val_acc, color=\"red\")\n#plt.plot(epochs, sleep_acc, color=\"black\")\nplt.plot(epochs, meditating_acc, color=\"orange\")\n#plt.plot(epochs, total_train_acc, color=\"green\")\nplt.legend(['total val accuracy', 'sleep accuracy', 'meditating accuracy', 'total train accuracy'])\n","metadata":{"execution":{"iopub.execute_input":"2023-03-25T13:51:58.867397Z","iopub.status.busy":"2023-03-25T13:51:58.866924Z","iopub.status.idle":"2023-03-25T13:51:58.966761Z","shell.execute_reply":"2023-03-25T13:51:58.965592Z","shell.execute_reply.started":"2023-03-25T13:51:58.867319Z"}},"execution_count":16,"outputs":[{"name":"stdout","output_type":"stream","text":"skipping\n"}]}]}